{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "import pandas, os, re\r\n",
    "\r\n",
    "def valid_amino_acid(amino_acid) :\r\n",
    "    if len(amino_acid) != 1 : return False\r\n",
    "    return amino_acid[0].isalpha()\r\n",
    "\r\n",
    "\r\n",
    "def valid_CleavageSite(Site) :\r\n",
    "    # print(Site)\r\n",
    "    for amino_acid in Site :\r\n",
    "        if not valid_amino_acid(amino_acid) :\r\n",
    "            return False\r\n",
    "    return True\r\n",
    "\r\n",
    "Sites, Names_Site = [], []\r\n",
    "\r\n",
    "for file in os.listdir('./CleavageSite') :\r\n",
    "\r\n",
    "    df = pandas.read_csv(os.path.join(os.path.abspath('./'), 'CleavageSite', file))\r\n",
    "    \r\n",
    "    rows = [row for row in df.iloc[:, 1:9].values if valid_CleavageSite(row)]\r\n",
    "    name = [file[:7] for i in range(len(rows))]\r\n",
    "\r\n",
    "    Sites = Sites + rows\r\n",
    "    Names_Site = Names_Site + name\r\n",
    "\r\n",
    "print('Total Sites: %d' % (len(Sites)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Sites: 743\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "AA_index = pandas.read_csv('AAidx.csv')\r\n",
    "AA_index = AA_index.dropna()\r\n",
    "\r\n",
    "AA_index.head()\r\n",
    "print(AA_index.shape[0])\r\n",
    "\r\n",
    "def transform(Site) :\r\n",
    "    ret = []\r\n",
    "    for amino_acid in Site :\r\n",
    "        if amino_acid not in AA_index.columns :\r\n",
    "            print('WTF')\r\n",
    "        ret = np.concatenate((ret, AA_index[amino_acid].iloc[:].values), axis = 0)\r\n",
    "    \r\n",
    "    return ret\r\n",
    "\r\n",
    "AA_Sites = np.array([transform(row) for row in Sites])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "531\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "def mRMR(AA_Sites) :\r\n",
    "    return\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "\r\n",
    "pca = PCA(n_components = 500).fit(AA_Sites)\r\n",
    "\r\n",
    "X_pca = pca.transform(AA_Sites)\r\n",
    "\r\n",
    "scaler = StandardScaler().fit(X_pca)\r\n",
    "X = scaler.transform(X_pca)\r\n",
    "\r\n",
    "print(X.shape)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "from sklearn.cluster import KMeans\r\n",
    "\r\n",
    "k = 10\r\n",
    "\r\n",
    "kmeans = KMeans(n_clusters = k, random_state = False).fit(X)\r\n",
    "\r\n",
    "y = kmeans.labels_\r\n",
    "\r\n",
    "print(len(y))\r\n",
    "print(y)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "743\n",
      "[9 2 0 9 0 8 8 8 0 7 7 6 8 0 2 6 0 8 9 8 8 8 8 0 8 8 7 0 7 0 7 6 7 0 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 0 8 8 8 1 2 7 2 6 0 9 8 2 0 5 5 0 0 8 8 5\n",
      " 8 0 2 9 8 7 0 9 7 7 8 7 0 5 0 0 9 5 0 7 7 2 0 8 8 7 7 3 8 7 7 5 8 0 9 7 8\n",
      " 3 8 8 7 8 8 8 8 0 0 0 9 7 5 2 7 9 2 7 8 8 2 7 8 8 3 2 2 7 8 3 7 8 3 2 0 0\n",
      " 2 8 7 7 2 0 8 7 7 1 0 8 1 2 0 8 6 7 7 0 0 7 8 7 9 7 7 5 7 8 2 1 9 2 0 8 8\n",
      " 7 0 7 9 0 8 6 7 7 2 5 1 1 4 5 8 6 7 7 8 6 8 0 8 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 5 5 5 5 3 3 5 3 4 9 3 3 5 5 4 2 4 4 5 5 4 5\n",
      " 8 3 3 5 5 3 9 5 5 5 5 4 4 4 4 9 5 5 5 5 9 5 3 3 5 4 4 4 3 2 3 4 3 3 3 3 1\n",
      " 3 4 8 9 3 3 4 5 5 5 3 5 3 5 5 8 3 9 3 5 4 3 9 3 5 3 2 5 3 4 3 3 5 3 3 3 9\n",
      " 5 3 4 4 5 4 9 9 3 5 9 9 5 9 3 4 4 9 4 4 3 4 4 4 5 4 4 4 3 5 4 3 4 1 4 4 5\n",
      " 4 4 3 7 4 4 4 4 5 4 3 4 4 4 4 5 4 5 4 3 4 3 4 9 4 9 3 3 1 1 3 1 3 3 7 8 2\n",
      " 7 3 1 3 4 3 1 5 5 3 5 1 3 3 5 1 3 3 5 1 3 3 5 1 3 5 5 3 5 3 3 5 5 1 1 3 1\n",
      " 3 3 3 3 9 3 3 8 8 4 3 3 3 3 3 3 4 3 3 4 4 5 1 1 3 5 5 3 5 5 9 5 9 5 9 5 3\n",
      " 5 3 1 9 3 5 5 2 2 1 1 1 1 2 1 1 1 5 1 5 1 4 1 1 1 5 5 1 2 1 1 5 1 4 1 1 1\n",
      " 3 5 2 2 2 1 4 1 1 1 2 1 5 4 1 3 5 1 1 3 1 3 2 2 2 2 1 2 1 5 1 1 2 1 2 3 3\n",
      " 5 2 2 1 1 5 4 4 3 3 1 1 1 4 1 1 3 2 4 1 2 1 1 1 1 5 4 1 2 2 1 1 1 1 2 2 1\n",
      " 5 1 1 1 1 5 1 1 5 5 1 2 3 4 1 1 1 5 5 1 2 1 1 5 1 4 1 1 1 3 5 2 2 2 1 4 1\n",
      " 3 5 1 1 1 1 2 1 5 4 1 3 5 1 1 3 1 3 2 2 4 2 2 1 2 5 1 8 5 9 1 1 2 1 2 3 3\n",
      " 5 1 2 2 1 3 5 4 4 3 3 1 1 1 1 1 1 5 1 3 2 5 4 1 2 1 1 1 1 3 2 3 5 4 1 3 0\n",
      " 7 8 2 6 7 7 8 8 6 7 6 6 0 7 6 0 7 7 7 2 6 7 8 6 0 0 0 0 8 1 2 7 6 0 9 2 7\n",
      " 9 8 7]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "\r\n",
    "Sequence, Names_Seq = [], []\r\n",
    "st = set()\r\n",
    "\r\n",
    "def valid_Protease(Protease) :\r\n",
    "    if len(Protease) == 0 : return False\r\n",
    "    if Protease in st : return False\r\n",
    "    st.add(Protease)\r\n",
    "    return True\r\n",
    "\r\n",
    "\r\n",
    "for file in os.listdir('./Protease') :\r\n",
    "\r\n",
    "    df = pandas.read_csv(os.path.join(os.path.abspath('./'), 'Protease', file))\r\n",
    "    \r\n",
    "    rows = [row for row in df.iloc[:, [5]].values if valid_Protease(str(row))]\r\n",
    "    name = [file[:7] for i in range(len(rows))]\r\n",
    "\r\n",
    "    Sequence = Sequence + rows\r\n",
    "    Names_Seq = Names_Seq + name\r\n",
    "\r\n",
    "print('Total Preteasae Sequences: %d' % (len(Sequence)))\r\n",
    "\r\n",
    "# print(Sequence)\r\n",
    "# print(Names_Seq)\r\n",
    "mx = 0\r\n",
    "for sq in Sequence :\r\n",
    "    if len(sq) > mx :\r\n",
    "        mx = len(str(sq))\r\n",
    "\r\n",
    "print(mx)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Preteasae Sequences: 1517\n",
      "337\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "def WeakClassifier() :\r\n",
    "\r\n",
    "    def __init__(self) :\r\n",
    "\r\n",
    "        return\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "class Adaboost() :\r\n",
    "    \r\n",
    "    def __init__(self, T = 10) :\r\n",
    "        \"\"\"\r\n",
    "          Parameters:\r\n",
    "            T: The number of weak classifiers which should be used.\r\n",
    "        \"\"\"\r\n",
    "        self.T = T\r\n",
    "        self.alphas = []\r\n",
    "        self.clfs = []\r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\r\n",
    "from keras.models import Model, Sequential\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "model = Sequential()\r\n",
    "model.add(Embedding(1000, 64, input_length=10))\r\n",
    "# 模型将输入一个大小为 (batch, input_length) 的整数矩阵。\r\n",
    "# 输入中最大的整数（即词索引）不应该大于 999 （词汇表大小）\r\n",
    "# 现在 model.output_shape == (None, 10, 64)，其中 None 是 batch 的维度。\r\n",
    "\r\n",
    "input_array = np.random.randint(1000, size=(32, 10))\r\n",
    "\r\n",
    "model.compile('rmsprop', 'mse')\r\n",
    "output_array = model.predict(input_array)\r\n",
    "\r\n",
    "print(input_array.shape, output_array)\r\n",
    "assert output_array.shape == (32, 10, 64)\r\n",
    "\r\n",
    "# max_len = 1500\r\n",
    "\r\n",
    "# def build_model() :\r\n",
    "    \r\n",
    "#     inputs = Input(name = 'inputs', shape = [max_len])\r\n",
    "#     layerr = Embedding(26, 50, input_length = max_len)(inputs)\r\n",
    "\r\n",
    "    \r\n",
    "\r\n",
    "\r\n",
    "# LSTMs = []\r\n",
    "\r\n",
    "# for i in range(k) :\r\n",
    "#     LSTMs.append(build_model())\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000014CDC50B4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "(32, 10) [[[ 0.02733015 -0.03791557 -0.00301259 ... -0.0229454  -0.02892692\n",
      "    0.02235457]\n",
      "  [-0.01952118 -0.04048399 -0.02147277 ... -0.02275592 -0.01743511\n",
      "    0.02591804]\n",
      "  [ 0.04423148  0.00738232  0.01370162 ... -0.01535945  0.01445539\n",
      "   -0.02999492]\n",
      "  ...\n",
      "  [-0.01389632  0.00216269 -0.01251178 ... -0.04027226 -0.02524598\n",
      "    0.02044672]\n",
      "  [ 0.03900999  0.04946211  0.02582154 ...  0.0245356  -0.03930964\n",
      "   -0.03027912]\n",
      "  [-0.04260153 -0.0351718  -0.01016019 ... -0.04544235  0.01063997\n",
      "    0.03335172]]\n",
      "\n",
      " [[-0.00925386  0.036912    0.02886871 ...  0.00156211  0.0072623\n",
      "    0.04670188]\n",
      "  [ 0.02121866  0.01783601  0.01368309 ...  0.0088901  -0.02831112\n",
      "    0.04993567]\n",
      "  [ 0.04313273  0.03185499 -0.04169626 ...  0.0386783   0.02622874\n",
      "    0.03778296]\n",
      "  ...\n",
      "  [ 0.02468964  0.00425301  0.02476433 ... -0.03888662  0.01792773\n",
      "   -0.03392973]\n",
      "  [ 0.02472682  0.0094886  -0.0266973  ... -0.01692218  0.00011845\n",
      "    0.00537697]\n",
      "  [-0.04898012  0.04833959 -0.02469771 ... -0.04297383 -0.04126786\n",
      "    0.03465668]]\n",
      "\n",
      " [[-0.02361796 -0.02096797 -0.013114   ... -0.00280968 -0.03967786\n",
      "   -0.01271626]\n",
      "  [-0.03939462 -0.01420473 -0.03864991 ...  0.02474388  0.02417116\n",
      "   -0.03982646]\n",
      "  [ 0.00335785  0.01840242 -0.04188174 ... -0.04740609 -0.01461595\n",
      "   -0.00974429]\n",
      "  ...\n",
      "  [-0.02283291  0.03328462 -0.02307472 ...  0.03358794 -0.03089769\n",
      "    0.00088298]\n",
      "  [-0.0089271  -0.01994445  0.00699115 ...  0.0414998  -0.0152887\n",
      "   -0.01393219]\n",
      "  [ 0.00403457 -0.00675184 -0.03132571 ...  0.00870775  0.01187963\n",
      "   -0.0466823 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.04263811  0.03484252  0.0325934  ... -0.00409005  0.0266019\n",
      "   -0.00115442]\n",
      "  [-0.01080691 -0.01592769 -0.00851747 ...  0.02728127 -0.0242488\n",
      "    0.0145766 ]\n",
      "  [-0.04798954 -0.00703391  0.02793695 ...  0.02222916 -0.03306762\n",
      "   -0.01154133]\n",
      "  ...\n",
      "  [-0.04898012  0.04833959 -0.02469771 ... -0.04297383 -0.04126786\n",
      "    0.03465668]\n",
      "  [ 0.01552243  0.03441392  0.04738152 ... -0.00509514 -0.02834911\n",
      "   -0.01717498]\n",
      "  [ 0.00765122  0.03392129 -0.00978837 ...  0.02637878  0.02786424\n",
      "    0.02564749]]\n",
      "\n",
      " [[-0.04260153 -0.0351718  -0.01016019 ... -0.04544235  0.01063997\n",
      "    0.03335172]\n",
      "  [-0.01875314 -0.0118403   0.00742102 ... -0.01757115  0.01402441\n",
      "    0.02670926]\n",
      "  [-0.00693226 -0.01045616  0.01243379 ...  0.03907695  0.00269473\n",
      "   -0.00336812]\n",
      "  ...\n",
      "  [-0.02756169 -0.04250352  0.03722363 ... -0.03325666 -0.03683908\n",
      "    0.04412873]\n",
      "  [ 0.00514726  0.01020247 -0.0444725  ...  0.04468897 -0.03492266\n",
      "   -0.02085712]\n",
      "  [ 0.04244188  0.03068799 -0.0244471  ...  0.02123268 -0.04594083\n",
      "   -0.03128737]]\n",
      "\n",
      " [[ 0.03664544  0.00698873 -0.00026157 ... -0.03717021  0.01875694\n",
      "   -0.01067936]\n",
      "  [ 0.00335785  0.01840242 -0.04188174 ... -0.04740609 -0.01461595\n",
      "   -0.00974429]\n",
      "  [ 0.0405177   0.00701442 -0.00272291 ... -0.00130875 -0.02099475\n",
      "    0.0124814 ]\n",
      "  ...\n",
      "  [-0.01880851 -0.0240202  -0.03583644 ...  0.03747033  0.01034952\n",
      "   -0.01615856]\n",
      "  [-0.01200434  0.00399677 -0.00240762 ...  0.02143687 -0.01687402\n",
      "   -0.02993572]\n",
      "  [-0.00579194  0.02799864 -0.03561191 ...  0.03343094  0.04237068\n",
      "    0.03087976]]]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "f27f2496960f23253b89e7b8bb5fad291f16c34ca6ee598496faa9251168aae6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}